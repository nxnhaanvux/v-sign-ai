# V-Sign AI - Vietnamese Sign Language to Text Translation

![V-Sign AI Logo](https://img.shields.io/badge/V--Sign-AI-blue?style=for-the-badge&logo=react)
![TensorFlow.js](https://img.shields.io/badge/TensorFlow.js-4.11-orange?style=for-the-badge&logo=tensorflow)
![React](https://img.shields.io/badge/React-18.2-61dafb?style=for-the-badge&logo=react)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Hands-green?style=for-the-badge)

**V-Sign AI** lÃ  má»™t há»‡ thá»‘ng nháº­n diá»‡n ngÃ´n ngá»¯ kÃ½ hiá»‡u Viá»‡t Nam (VSL - Vietnamese Sign Language) cháº¡y hoÃ n toÃ n trÃªn trÃ¬nh duyá»‡t web, sá»­ dá»¥ng AI Ä‘á»ƒ dá»‹ch kÃ½ hiá»‡u sang vÄƒn báº£n thá»i gian thá»±c.

## ğŸ¯ Má»¥c tiÃªu

PhÃ¡ bá» rÃ o cáº£n giao tiáº¿p cho **2.5 triá»‡u ngÆ°á»i khiáº¿m thÃ­nh táº¡i Viá»‡t Nam**, Ä‘áº·c biá»‡t trong cÃ¡c tÃ¬nh huá»‘ng y táº¿ kháº©n cáº¥p.

## âœ¨ TÃ­nh nÄƒng

- âœ… **100% Client-side Processing** - Dá»¯ liá»‡u khÃ´ng bao giá» rá»i khá»i thiáº¿t bá»‹
- âš¡ **Real-time Translation** - Äá»™ trá»… chá»‰ 50-100ms
- ğŸ”’ **Privacy First** - KhÃ´ng lÆ°u trá»¯ hay gá»­i video lÃªn server
- ğŸ†“ **Free & Open Source** - Miá»…n phÃ­ hoÃ n toÃ n, khÃ´ng giá»›i háº¡n
- ğŸ“± **Cross-platform** - Cháº¡y trÃªn má»i trÃ¬nh duyá»‡t hiá»‡n Ä‘áº¡i
- ğŸ¨ **Modern UI** - Giao diá»‡n Ä‘áº¹p, responsive, dá»… sá»­ dá»¥ng

## ğŸ¥ CÃ¡c KÃ½ hiá»‡u Y táº¿ CÆ¡ báº£n

Hiá»‡n táº¡i há»— trá»£ 5 kÃ½ hiá»‡u y táº¿ thiáº¿t yáº¿u:

1. **Äau** - Chá»‰ vÃ o vÃ¹ng Ä‘au
2. **BÃ¡c sÄ©** - Cáº§n gáº·p bÃ¡c sÄ©
3. **Cáº§n giÃºp** - Cáº§n trá»£ giÃºp kháº©n cáº¥p
4. **Thuá»‘c** - Cáº§n thuá»‘c/Ä‘iá»u trá»‹
5. **Cáº£m Æ¡n** - Cáº£m Æ¡n sá»± giÃºp Ä‘á»¡

## ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webcam    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MediaPipe Hands â”‚ â†’ TrÃ­ch xuáº¥t 21 landmarks/hand
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sequence Buffer â”‚ â†’ LÆ°u 30 frames (x, y, z coordinates)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LSTM Model      â”‚ â†’ TensorFlow.js inference
â”‚  (TensorFlow.js) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prediction      â”‚ â†’ Hiá»ƒn thá»‹ vÄƒn báº£n + confidence
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Cáº¥u trÃºc ThÆ° má»¥c

```
v-sign-ai/
â”œâ”€â”€ train_model.py              # Script training LSTM model
â”œâ”€â”€ convert_to_tfjs.py          # Convert model sang TensorFlow.js
â”œâ”€â”€ generate_sample_data.py     # Táº¡o dá»¯ liá»‡u máº«u
â”œâ”€â”€ dataset/                    # Dá»¯ liá»‡u training
â”‚   â”œâ”€â”€ Äau/
â”‚   â”œâ”€â”€ BÃ¡c_sÄ©/
â”‚   â”œâ”€â”€ Cáº§n_giÃºp/
â”‚   â”œâ”€â”€ Thuá»‘c/
â”‚   â””â”€â”€ Cáº£m_Æ¡n/
â”œâ”€â”€ tfjs_model/                 # MÃ´ hÃ¬nh Ä‘Ã£ convert
â”‚   â”œâ”€â”€ model.json
â”‚   â”œâ”€â”€ group1-shard1of1.bin
â”‚   â””â”€â”€ labels.json
â””â”€â”€ react-app/                  # Web application
    â”œâ”€â”€ public/
    â”‚   â””â”€â”€ tfjs_model/        # Copy mÃ´ hÃ¬nh vÃ o Ä‘Ã¢y
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ LoadingScreen.jsx
    â”‚   â”‚   â”œâ”€â”€ Header.jsx
    â”‚   â”‚   â”œâ”€â”€ CameraSection.jsx
    â”‚   â”‚   â”œâ”€â”€ PredictionSection.jsx
    â”‚   â”‚   â””â”€â”€ InfoPanel.jsx
    â”‚   â”œâ”€â”€ main.jsx
    â”‚   â””â”€â”€ index.css
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.js
```

## ğŸš€ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t & Cháº¡y

### BÆ°á»›c 1: Clone Repository

```bash
git clone https://github.com/your-username/v-sign-ai.git
cd v-sign-ai
```

### BÆ°á»›c 2: Training Model (TÃ¹y chá»n)

Náº¿u báº¡n muá»‘n train láº¡i model:

```bash
# CÃ i Ä‘áº·t Python dependencies
pip install tensorflow tensorflowjs scikit-learn numpy matplotlib seaborn

# Táº¡o dá»¯ liá»‡u máº«u (cho testing)
python generate_sample_data.py

# Training model
python train_model.py

# Convert sang TensorFlow.js
python convert_to_tfjs.py
```

### BÆ°á»›c 3: Setup Web App

```bash
cd react-app

# CÃ i Ä‘áº·t dependencies
npm install

# Copy model vÃ o public folder
cp -r ../tfjs_model public/

# Cháº¡y development server
npm run dev
```

Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p: `http://localhost:3000`

### BÆ°á»›c 4: Build cho Production

```bash
npm run build

# Serve static files
npm run preview
```

## ğŸ“Š Model Architecture

```python
Model: "VSIgn_LSTM"
_________________________________________________________________
Layer (type)                Output Shape              Param #   
=================================================================
lstm_1 (LSTM)              (None, 30, 128)           98304     
batch_normalization         (None, 30, 128)           512       
dropout                     (None, 30, 128)           0         
lstm_2 (LSTM)              (None, 64)                49408     
batch_normalization         (None, 64)                256       
dropout                     (None, 64)                0         
dense_1 (Dense)            (None, 64)                4160      
dropout                     (None, 64)                0         
output (Dense)             (None, 5)                 325       
=================================================================
Total params: 152,965
Trainable params: 152,581
Non-trainable params: 384
```

### Hyperparameters

- **Input Shape**: (30, 63) - 30 frames Ã— 63 features (21 landmarks Ã— 3 coordinates)
- **LSTM Units**: 128 â†’ 64
- **Dropout Rate**: 0.3, 0.3, 0.2
- **Optimizer**: Adam (lr=0.001)
- **Loss**: Sparse Categorical Crossentropy
- **Batch Size**: 32
- **Max Epochs**: 100 (with early stopping)

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Training Accuracy | 95%+ |
| Validation Accuracy | 90%+ |
| Inference Time (Browser) | 50-100ms |
| Model Size (Quantized) | ~3MB |
| FPS | 20-30 |

## ğŸ”§ CÃ´ng nghá»‡ Sá»­ dá»¥ng

### Frontend
- **React 18** - UI Framework
- **Vite** - Build tool
- **Tailwind CSS** - Styling
- **react-webcam** - Camera access

### AI & ML
- **TensorFlow.js** - Browser ML inference
- **MediaPipe Hands** - Hand landmark detection
- **LSTM** - Sequence modeling

### Training
- **TensorFlow/Keras** - Model training
- **Python 3.8+** - Backend
- **NumPy** - Data processing

## ğŸ“ CÃ¡ch Thu tháº­p Dá»¯ liá»‡u Thá»±c táº¿

### PhÆ°Æ¡ng phÃ¡p 1: Web-based Data Collection Tool

Táº¡o má»™t trang web Ä‘Æ¡n giáº£n Ä‘á»ƒ ghi láº¡i landmarks:

```javascript
// Pseudo-code
function recordGesture(gestureName) {
  const frames = [];
  
  // Thu tháº­p 30 frames
  for (let i = 0; i < 30; i++) {
    const landmarks = await hands.getLandmarks();
    frames.push(landmarks);
    await sleep(33); // ~30fps
  }
  
  // LÆ°u vÃ o JSON
  saveToFile({
    gesture: gestureName,
    sequences: [{ frames }]
  });
}
```

### PhÆ°Æ¡ng phÃ¡p 2: MediaPipe + OpenCV (Python)

```python
import mediapipe as mp
import cv2
import json

mp_hands = mp.solutions.hands
hands = mp_hands.Hands()

# Má»Ÿ webcam vÃ  ghi landmarks...
```

## ğŸ“ Training Tips

1. **Äa dáº¡ng hÃ³a dá»¯ liá»‡u**:
   - Thu tháº­p tá»« nhiá»u ngÆ°á»i khÃ¡c nhau (nam/ná»¯, tráº»/giÃ )
   - CÃ¡c gÃ³c nhÃ¬n khÃ¡c nhau
   - Äiá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau
   - Tá»‘c Ä‘á»™ thá»±c hiá»‡n khÃ¡c nhau

2. **Data Augmentation**:
   - Random rotation (Â±15Â°)
   - Random scaling (0.9-1.1x)
   - Gaussian noise (Ïƒ=0.01)
   - Time warping

3. **Balanced Dataset**:
   - Ãt nháº¥t 500-1000 samples má»—i kÃ½ hiá»‡u
   - Äáº£m báº£o cÃ¢n báº±ng sá»‘ lÆ°á»£ng giá»¯a cÃ¡c class

## ğŸŒ Deployment

### Netlify / Vercel (Recommended)

```bash
# Build
npm run build

# Deploy vá»›i Netlify CLI
netlify deploy --prod --dir=dist

# Hoáº·c Vercel CLI
vercel --prod
```

### GitHub Pages

```bash
# CÃ i Ä‘áº·t gh-pages
npm install -D gh-pages

# ThÃªm vÃ o package.json
"scripts": {
  "predeploy": "npm run build",
  "deploy": "gh-pages -d dist"
}

# Deploy
npm run deploy
```

## ğŸ¤ Contributing

ChÃºng tÃ´i ráº¥t hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! Vui lÃ²ng:

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i **MIT License** - xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t chi tiáº¿t.

## ğŸ‘¥ Team

- **Developers**: [Your Name]
- **Advisors**: [Advisor Names]

## ğŸ“§ Contact

- Email: your-email@example.com
- GitHub: [@your-username](https://github.com/your-username)

## ğŸ™ Acknowledgments

- **MediaPipe Team** - Cung cáº¥p hand tracking solution
- **TensorFlow.js Team** - Browser-based ML framework
- **Vietnamese Deaf Community** - Inspiration vÃ  feedback

## ğŸ“š References

1. MediaPipe Hands: https://google.github.io/mediapipe/solutions/hands
2. TensorFlow.js: https://www.tensorflow.org/js
3. LSTM Networks: https://colah.github.io/posts/2015-08-Understanding-LSTMs/

---

**Made with â¤ï¸ for the Vietnamese Deaf Community**
